# Sage记忆系统数据丢失问题分析与解决方案

**执行时间:** 2025-07-26 21:32:40  
**任务类型:** 系统架构问题诊断与解决方案设计  
**严重程度:** 致命 (Critical) - 影响整个项目价值

## 问题概述

### 发现的致命问题
Sage记忆系统目前只保存约**10%**的有价值交互数据，丢失了90%的关键开发信息：
- ❌ 工具调用参数和执行结果  
- ❌ Claude的推理过程 (thinking blocks)
- ❌ ZEN工具的AI-to-AI专家分析
- ❌ 错误信息和调试traceback
- ❌ 性能数据和执行时间
- ❌ 多轮工具调用的上下文关联

### 根本原因分析

#### 1. 数据提取逻辑缺陷
**文件:** `/Users/jet/Sage/hooks/scripts/sage_archiver.py`  
**问题位置:** Lines 135-136, 150-151

```python
# 当前的致命缺陷代码
if isinstance(content_item, dict) and content_item.get('type') == 'text':
    text_content.append(content_item.get('text', ''))
```

**问题分析:**
- 只提取 `type == 'text'` 的内容
- 完全忽略 `type == 'tool_use'`, `type == 'tool_result'` 等关键数据
- transcript.jsonl 中包含的丰富工具调用信息被直接丢弃

#### 2. 存储架构局限性
**文件:** `/Users/jet/Sage/sage_core/memory/manager.py`  
**问题位置:** Line 55

```python
# 过度简化的数据合并
combined_text = f"{content.user_input}\n{content.assistant_response}"
```

**问题分析:**
- 只向量化最终的文本交换
- 丢失了工具调用的语义信息
- 无法检索基于工具使用模式的历史经验

## 技术调研发现

### Claude Code Hooks 能力分析
基于官方文档 `https://docs.anthropic.com/en/docs/claude-code/hooks`：

✅ **可捕获的数据类型:**
- Tool usage (pre and post execution)
- User prompts and notifications  
- Agent stopping events
- Tool-specific inputs/outputs

✅ **执行时机:**
- PreToolUse: 工具执行前
- PostToolUse: 工具执行后
- UserPromptSubmit: 用户提交时
- Stop: 会话结束时

✅ **数据访问能力:**
- Session ID和transcript路径
- 工具调用的完整上下文
- JSON格式的结构化数据

## 解决方案架构

### 方案一: 多层Hook数据捕获 (推荐)

#### 1.1 实现 PreToolUse Hook
```bash
# 新增文件位置
/Users/jet/Sage/hooks/scripts/sage_pre_tool_capture.py
```

**功能设计:**
- 捕获工具调用前的完整状态
- 记录工具参数、上下文、环境信息
- 生成唯一调用ID关联整个调用链

#### 1.2 实现 PostToolUse Hook  
```bash
# 新增文件位置
/Users/jet/Sage/hooks/scripts/sage_post_tool_capture.py
```

**功能设计:**
- 捕获工具执行结果、错误、性能数据
- 关联PreToolUse的调用ID
- 特别处理ZEN工具的AI专家分析结果

#### 1.3 增强 Stop Hook (现有archiver改造)
**文件:** `/Users/jet/Sage/hooks/scripts/sage_archiver.py`

**改造重点:**
```python
# 替换当前的text-only提取逻辑
def extract_complete_interaction_chain(self, transcript_path: str):
    """提取完整的交互链数据"""
    for content_item in content_list:
        content_type = content_item.get('type')
        
        if content_type == 'text':
            # 保存文本内容
            text_content.append(content_item.get('text', ''))
            
        elif content_type == 'tool_use':
            # 保存工具调用信息
            tool_calls.append({
                'name': content_item.get('name'),
                'parameters': content_item.get('input', {}),
                'id': content_item.get('id')
            })
            
        elif content_type == 'tool_result':
            # 保存工具执行结果
            tool_results.append({
                'tool_use_id': content_item.get('tool_use_id'),
                'content': content_item.get('content'),
                'is_error': content_item.get('is_error', False)
            })
```

### 方案二: 数据存储架构重设计

#### 2.1 新的数据模型设计

```python
# 新增接口定义
class EnhancedMemoryContent:
    session_id: str
    timestamp: datetime
    user_input: str
    assistant_response: str
    
    # 新增字段
    tool_calls: List[ToolCall]
    tool_results: List[ToolResult] 
    thinking_process: Optional[str]
    error_traces: List[ErrorTrace]
    performance_metrics: Dict[str, Any]
    interaction_metadata: Dict[str, Any]
```

#### 2.2 分层向量化策略

**文本向量:** 用户输入 + 助手回复  
**工具向量:** 工具调用描述 + 参数 + 结果摘要  
**推理向量:** thinking blocks + 错误分析过程  
**综合向量:** 融合多个向量的加权平均

#### 2.3 数据库表结构扩展

```sql
-- 基础记忆表 (现有)
memories (id, session_id, user_input, assistant_response, embedding, metadata, created_at)

-- 新增工具调用表
tool_interactions (
    id UUID PRIMARY KEY,
    memory_id UUID REFERENCES memories(id),
    tool_name VARCHAR(100),
    tool_parameters JSONB,
    tool_result JSONB,
    execution_time_ms INTEGER,
    is_error BOOLEAN,
    call_sequence INTEGER
);

-- 新增推理过程表  
thinking_processes (
    id UUID PRIMARY KEY,
    memory_id UUID REFERENCES memories(id),
    thinking_content TEXT,
    thinking_embedding VECTOR(4096),
    stage VARCHAR(50) -- pre_tool, post_tool, analysis, etc.
);
```

### 方案三: 异步数据处理流水线

#### 3.1 实时数据采集 (Hook层)
- 轻量级数据捕获，避免影响用户体验
- 写入消息队列 (Redis/RabbitMQ)

#### 3.2 异步数据处理 (Worker层)  
- 后台worker处理完整的数据解析
- 向量化计算
- 数据持久化

#### 3.3 性能监控
- 采集延迟监控
- 队列长度告警
- 存储空间使用率

## 实施计划

### 第一阶段: 紧急修复 (1-2天)
- [x] **已发现问题:** 识别archiver.py的text-only提取缺陷
- [ ] **快速修复:** 扩展extract_last_conversation方法支持工具调用
- [ ] **验证测试:** 使用ZEN工具测试完整数据捕获

### 第二阶段: Hook增强 (3-5天)
- [ ] **实现PreToolUse Hook:** 捕获工具调用前状态
- [ ] **实现PostToolUse Hook:** 捕获执行结果和分析
- [ ] **集成测试:** 验证多Hook协调工作

### 第三阶段: 存储架构升级 (1周)
- [ ] **数据库表结构扩展:** 支持工具调用和推理数据
- [ ] **向量化策略升级:** 多层次向量化
- [ ] **查询接口重构:** 支持基于工具使用模式的检索

### 第四阶段: 性能优化 (1周)  
- [ ] **异步处理流水线:** 解耦数据采集和处理
- [ ] **批量向量化:** 提升向量计算效率
- [ ] **缓存策略:** 常用查询结果缓存

## 预期效果

### 数据保存完整性
- **当前:** ~10% 数据保存率
- **目标:** ~95% 数据保存率

### 知识检索能力  
- ✅ 可以检索"如何使用ZEN debug工具"
- ✅ 可以查找"PostgreSQL连接错误的解决方案"  
- ✅ 可以复用"Docker配置错误的排查经验"
- ✅ 可以学习"性能优化的具体实施步骤"

### 开发效率提升
- 历史调试经验的快速复用
- 错误模式的智能识别
- 工具使用最佳实践的积累

## 风险评估

### 技术风险
- **数据量暴增:** 预计存储需求增加5-10倍
- **向量化成本:** 计算资源需求增加
- **查询复杂度:** 多表关联的性能影响

### 缓解措施
- 分级存储策略 (热/冷数据)
- 异步向量化处理
- 数据库索引优化
- 定期数据归档和清理

## 技术实现建议

### 立即可行的快速修复
1. **修改 sage_archiver.py** 第135-151行的提取逻辑
2. **扩展 MemoryContent 接口** 支持工具调用数据
3. **验证端到端数据流** 确保修复生效

### 长期架构演进
1. **渐进式Hook实现** 避免破坏现有功能
2. **向后兼容设计** 现有数据迁移策略  
3. **监控和告警** 实时跟踪改进效果

---

## 结论

这是一个影响项目核心价值的致命问题，但也是一个明确可解决的技术挑战。通过系统性的架构改进，Sage可以从"丢失90%价值信息"转变为"完整保存开发知识资产"的强大记忆系统。

**建议优先级:** 🔴 **最高优先级** - 立即启动第一阶段修复